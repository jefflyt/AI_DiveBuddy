# Step 2.3.6: Integrate Chat API Route

**Part of:** PR 2.3 - Google AI Agent Framework Integration  
**Focus:** Connect Google AI Agent Framework to Next.js API route with streaming  
**Estimated Time:** 20 minutes

## Overview

Create the Next.js API route that exposes the orchestrator agent as a streaming chat endpoint. This integrates the entire multi-agent system with the frontend using Vercel AI SDK.

## Pre-Step Checklist

- [ ] **Completed:** Step 2.3.5 - Orchestrator agent created
- [ ] **Installed:** Vercel AI SDK (`ai` package)
- [ ] **Frontend:** Chat UI components ready (from PR 1.4)

## Implementation

### Goal

Build `/api/chat` endpoint that handles streaming agent responses with session management.

### Step-by-Step Instructions

#### Step 1: Install Vercel AI SDK

```bash
npm install ai
```

#### Step 2: Create Chat API Route

Create `src/app/api/chat/route.ts`:

```typescript
import { StreamingTextResponse } from 'ai'
import { orchestrator } from '@/lib/agents/orchestrator'
import { AgentMiddleware } from '@/lib/agents/middleware'
import { NextRequest, NextResponse } from 'next/server'

export const runtime = 'edge' // Use Edge Runtime for faster cold starts

export async function POST(req: NextRequest) {
  try {
    const { message, sessionId, userId } = await req.json()
    
    // Validate input
    if (!message || typeof message !== 'string') {
      return NextResponse.json(
        { error: 'Message is required' },
        { status: 400 }
      )
    }
    
    // Content moderation
    const moderation = AgentMiddleware.moderateContent(message)
    if (!moderation.allowed) {
      return NextResponse.json(
        { error: moderation.reason },
        { status: 400 }
      )
    }
    
    // Rate limiting
    const rateLimitKey = sessionId || userId || 'anonymous'
    if (!AgentMiddleware.checkRateLimit(rateLimitKey)) {
      return NextResponse.json(
        { error: 'Rate limit exceeded. Please wait a moment.' },
        { status: 429 }
      )
    }
    
    // Start timer for metrics
    const startTime = Date.now()
    
    // Handle message through orchestrator
    const result = await orchestrator.handleMessage({
      message,
      sessionId,
      userId,
    })
    
    // Log metrics
    AgentMiddleware.logInteraction({
      sessionId: result.sessionId,
      userId,
      intent: result.intent,
      agent: result.agentUsed,
      responseTime: Date.now() - startTime,
      success: true,
    })
    
    // Return response with metadata
    return NextResponse.json({
      response: result.response,
      sessionId: result.sessionId,
      intent: result.intent,
      agent: result.agentUsed,
    })
  } catch (error) {
    console.error('[Chat API] Error:', error)
    
    return NextResponse.json(
      {
        error: 'Failed to process message',
        details: error instanceof Error ? error.message : 'Unknown error',
      },
      { status: 500 }
    )
  }
}

// GET: Retrieve session history
export async function GET(req: NextRequest) {
  try {
    const { searchParams } = new URL(req.url)
    const sessionId = searchParams.get('sessionId')
    
    if (!sessionId) {
      return NextResponse.json(
        { error: 'Session ID required' },
        { status: 400 }
      )
    }
    
    const history = await orchestrator.getSessionHistory(sessionId)
    
    return NextResponse.json(history)
  } catch (error) {
    console.error('[Chat API] GET Error:', error)
    
    return NextResponse.json(
      { error: 'Failed to fetch session history' },
      { status: 500 }
    )
  }
}

// DELETE: Clear session
export async function DELETE(req: NextRequest) {
  try {
    const { searchParams } = new URL(req.url)
    const sessionId = searchParams.get('sessionId')
    
    if (!sessionId) {
      return NextResponse.json(
        { error: 'Session ID required' },
        { status: 400 }
      )
    }
    
    await orchestrator.resetSession(sessionId)
    
    return NextResponse.json({ success: true })
  } catch (error) {
    console.error('[Chat API] DELETE Error:', error)
    
    return NextResponse.json(
      { error: 'Failed to delete session' },
      { status: 500 }
    )
  }
}
```

#### Step 3: Create Streaming API Route (Alternative)

Create `src/app/api/chat/stream/route.ts` for streaming responses:

```typescript
import { StreamingTextResponse } from 'ai'
import { sessionManager } from '@/lib/agents/session-manager'
import { AgentFactory } from '@/lib/agents/agent-factory'
import { intentClassifierTool } from '@/lib/agents/tools/intent-classifier'
import { StreamingHandler } from '@/lib/agents/streaming-handler'
import { AgentMiddleware } from '@/lib/agents/middleware'
import { NextRequest } from 'next/server'

export const runtime = 'edge'

export async function POST(req: NextRequest) {
  try {
    const { message, sessionId, userId } = await req.json()
    
    // Validation
    const moderation = AgentMiddleware.moderateContent(message)
    if (!moderation.allowed) {
      return new Response(moderation.reason, { status: 400 })
    }
    
    // Get/create session
    const session = await sessionManager.getOrCreate(sessionId, userId)
    await sessionManager.addMessage(session.id, 'user', message)
    
    // Classify intent
    const intentResult = await intentClassifierTool.execute({
      message,
      conversationHistory: session.messages.slice(-5).map(m => m.content),
    })
    
    const intent = intentResult.success ? intentResult.intent : 'general'
    const agent = AgentFactory.getAgent(intent)
    
    // Create streaming response
    const prompt = `User: ${message}\n\nPlease respond based on your role and context.`
    const stream = StreamingHandler.streamResponse(prompt, session)
    
    // Convert to ReadableStream
    const readableStream = StreamingHandler.toReadableStream(stream)
    
    // Return streaming response
    return new StreamingTextResponse(readableStream, {
      headers: {
        'X-Session-Id': session.id,
        'X-Intent': intent,
        'X-Agent': AgentFactory.getAgentName(intent),
      },
    })
  } catch (error) {
    console.error('[Chat Stream API] Error:', error)
    return new Response('Streaming failed', { status: 500 })
  }
}
```

#### Step 4: Create Sessions API Route

Create `src/app/api/sessions/route.ts`:

```typescript
import { NextRequest, NextResponse } from 'next/server'
import { orchestrator } from '@/lib/agents/orchestrator'
import { createClient } from '@/lib/supabase/server'

export async function GET(req: NextRequest) {
  try {
    // Get authenticated user
    const supabase = createClient()
    const { data: { user }, error: authError } = await supabase.auth.getUser()
    
    if (authError || !user) {
      return NextResponse.json(
        { error: 'Unauthorized' },
        { status: 401 }
      )
    }
    
    // Get user's sessions
    const sessions = await orchestrator.getUserSessions(user.id)
    
    return NextResponse.json({ sessions })
  } catch (error) {
    console.error('[Sessions API] Error:', error)
    return NextResponse.json(
      { error: 'Failed to fetch sessions' },
      { status: 500 }
    )
  }
}
```

#### Step 5: Update Chat Hook (Frontend)

Update `src/hooks/useChat.ts`:

```typescript
import { useState, useCallback } from 'react'

export interface Message {
  id: string
  role: 'user' | 'agent'
  content: string
  timestamp: Date
}

export function useChat(initialSessionId?: string) {
  const [messages, setMessages] = useState<Message[]>([])
  const [sessionId, setSessionId] = useState<string | undefined>(initialSessionId)
  const [isLoading, setIsLoading] = useState(false)
  const [error, setError] = useState<string | null>(null)
  
  const sendMessage = useCallback(async (message: string) => {
    if (!message.trim()) return
    
    // Add user message optimistically
    const userMessage: Message = {
      id: crypto.randomUUID(),
      role: 'user',
      content: message,
      timestamp: new Date(),
    }
    setMessages(prev => [...prev, userMessage])
    setIsLoading(true)
    setError(null)
    
    try {
      const response = await fetch('/api/chat', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          message,
          sessionId,
        }),
      })
      
      if (!response.ok) {
        const errorData = await response.json()
        throw new Error(errorData.error || 'Failed to send message')
      }
      
      const data = await response.json()
      
      // Update session ID if new
      if (data.sessionId && !sessionId) {
        setSessionId(data.sessionId)
      }
      
      // Add agent response
      const agentMessage: Message = {
        id: crypto.randomUUID(),
        role: 'agent',
        content: data.response,
        timestamp: new Date(),
      }
      setMessages(prev => [...prev, agentMessage])
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Unknown error')
      console.error('Chat error:', err)
    } finally {
      setIsLoading(false)
    }
  }, [sessionId])
  
  const clearChat = useCallback(async () => {
    if (sessionId) {
      await fetch(`/api/chat?sessionId=${sessionId}`, { method: 'DELETE' })
    }
    setMessages([])
    setSessionId(undefined)
    setError(null)
  }, [sessionId])
  
  return {
    messages,
    sessionId,
    isLoading,
    error,
    sendMessage,
    clearChat,
  }
}
```

## Verification Checklist

- [ ] `src/app/api/chat/route.ts` created with POST/GET/DELETE methods
- [ ] `src/app/api/chat/stream/route.ts` created for streaming (optional)
- [ ] `src/app/api/sessions/route.ts` created for session management
- [ ] `src/hooks/useChat.ts` updated to use new API
- [ ] Vercel AI SDK (`ai`) installed
- [ ] Edge runtime configured for faster responses
- [ ] Rate limiting working correctly
- [ ] Session persistence verified

## Testing

Test the API routes:

```bash
# Test chat endpoint
curl -X POST http://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "What is buoyancy control?"}'

# Test session history
curl "http://localhost:3000/api/chat?sessionId=YOUR_SESSION_ID"

# Test session delete
curl -X DELETE "http://localhost:3000/api/chat?sessionId=YOUR_SESSION_ID"
```

## Troubleshooting

| Issue | Solution |
|-------|----------|
| Edge runtime errors | Remove `export const runtime = 'edge'` to use Node.js runtime |
| CORS errors | Add CORS headers if calling from external domain |
| Session not persisting | Check Supabase credentials and RLS policies |
| Rate limit too aggressive | Adjust limits in `AgentMiddleware.checkRateLimit` |
| Streaming not working | Use regular POST endpoint instead of stream |

## Files Created

- âœ… Created: `src/app/api/chat/route.ts` - Main chat API endpoint
- âœ… Created: `src/app/api/chat/stream/route.ts` - Streaming chat endpoint
- âœ… Created: `src/app/api/sessions/route.ts` - Session management API
- âœ… Modified: `src/hooks/useChat.ts` - Updated chat hook

## What Comes Next

**PR 2.3 Complete!** ðŸŽ‰

You have successfully integrated the Google AI Agent Framework:

- âœ… Orchestrator agent with intent routing
- âœ… Education and Trip Planning specialist agents
- âœ… Vector search RAG tools
- âœ… Session management with MCP pattern
- âœ… Streaming API endpoints
- âœ… Rate limiting and moderation

**Next Steps:**

1. Test the complete chat flow end-to-end
2. Seed knowledge base with sample content
3. Move to **Phase 3: Education Feature** (PR 3.1 - Create OW/AOW content)
